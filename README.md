# SOABB1
This online repository contains the data processing and analysis scripts underlying the article entitled ‘Infants recognise their own voice well before recognising their own face’, as well as the anonymised tabulated data associated with this work. 

## Repository structure

### Scripts

Python codes: 
* **analyses_MT_gaze.ipynb** : compares infant behaviour in the mirror task before and after the red mark has been placed on their forehead.
* **Script1_cutFiles.ipynb** : processes audio recordings by separating infant vocalisations from other sounds and merging vocalisations that are the same type and produced by the same child in the same phase which are less than 500ms apart. The results are stored in the .csv file with this name structure: "NX_sounds_details".
* **Script2_extractPitch.ipynb** : extracts the fundamental frequency (f0), harmonic-to-noise (HNR) and root mean square (RMS) of the vocalisations in each phase of the experiment (experimental and baseline) with Praat, based on the .csv file generated by Script1_cutFiles.ipynb. To run this script, download **Pitch_BB.praat** and **utilities_SOA.py** (both included in this repository). Make sure to update your local path to Pitch_BB.praat inside utilities_SOA.py. It generates a .csv file with the following name structure: "f0_HNR_RMS_NX.csv" and another one containing f0 values over time (non averaged) per vocalisation, with this name structure: "NX_f0_overtime.csv" 
* **Script3_plotResults.ipynb** : preprocesses data, plots results and runs descriptive statistics based on the results file with the following format: "f0_HNR_RMS_NX.csv". It also generates 4 different scripts for subsequent statistical analysis in R. These have the following format and overall content: "NX_B.csv" (containing the standardised f0 difference between experimental and baseline phase per individual vocalisation), "N72_both.csv" (containing also the caregiver' vocalisations), "N72_concat.csv" (containing the standardised difference in the f0 produced between phases calculated over concatenated data, employed in the main analysis in the manuscript), "N72_phases.csv" (the average difference between the unmodified and modified sound in each phase, per infant).  
* **Script4_f0overtime.ipynb** allows to visualise f0 variation over time, overall and per vocalisation.

R code:
* **SOABB1_stat_analyses.R** : runs all the statistical models in the main text and supplementary materials.

### Datasets

**References_audios_bb.xlsx** contains the demographic details about the participants (e.g., age, languages spopken, sex, date of birth) as well as details and notes concerning the test (e.g., date, timing of f0 modification relative to the onset of the recording, etc). It includes the following information relevant for the study:
* _BB_ : unique participant ID
* Whether the participant was successfully tested or not due to technical errors or other reasons (_Tech_error_ , _No_data_ , _Tested_)
* _DDT_ : date of test
* _DDN_ : date of birth
* _age_ : age in decimal months
* _Mois_ : age in months
* _sexe_ : sex
* _Timing_modif_ : the timing in minutes when the f0 mdification was applied
* _timing_modif_sec_ : the above but in seconds  
* _Type_modif_ : whether the f0 was shifted up (100) or down (-100) for that participant
*  _Ordre_miroir_ : order of execution of the mirror task and interaction, which was counterbalanced
*  Demographic information such as whether the child was exposed to multiple languages or not (_monolingue_), whether they could hold their head up (_tete_) and sitting up (_assis_), whether they locomoted autonomously (_deplacement_), information about the type of vocalisations they produced (_vocalisation_), whether the child had had ear infections or hearing problems (_audition_pb_). This information was collected in a questionnaire which is part of the laboratory’s standard intake protocol, to collect background information for multiple ongoing studies.
*  _Mirror_recognition_ :  Whether the child touched the red mark on their forehead, showing signs of recognising the reflection as themselves (0 = No, 1 = Yes).

**N_sounds_details.csv** is generated at the end of Script 1 and contains the start and end times of parent and child vocalisations and the vocalisation type, the phase in which it was produced (BL: baseline - before f0 modification or EXP: experimental - after f0 modification). It does not yet include the f0, which is extracted in Script 2. This file contains the same information as _N_f0_HNR_RMS.csv_ (see below) minus the information relative to the f0, HNR and RMS.

**N_f0_HNR_RMS.csv** is the final dataset generated at the end of Script 2. Script 3 runs on this file. Relevant information is included in the following columns:
* _file_ : the audio filename;
* _start_times_ : start time of each vocalisation in seconds from the start of the audio recording
* _stop_times_ : end time of each vocalisation in seconds from the start of the audio recording
* _duration_ : the duration of the vocalisation
* _phase_ : either baseline (BL) or experimental (EXP)
* _who_ : dentifies the producer of the vocalisation, namely the infant (_B_), the caregiver (_M_), overlapping vocalisations from both (_CoV_), two non-overlapping vocalisations within the same segment (_T_). The latter category occurred mainly in the first phase of the study, when audio files were segmented using an automatic machine learning algorithm (https://github.com/LAAC-LSCP/VTC), before we transitioned to manual coding, which proved more reliable for our purposes and our kind of data.
* _voc_type_ : the type of vocalisation being produced by the infant, based on the classification in Buder et al. (2013).
* Background information collected via the questionnaire upon participant arrival at the lab (see above).
* _cond_ : condition (p100 = upward, m100 = downward, neutre = neutral)
* _f0m_NM_ : the average f0 over each individual vocalisation as produced by the child
* _f0sd_NM_ : the standard deviation of f0 over each individual vocalisation as produced by the infant
* _f0m_M_ : the average f0 over each individual vocalisation played back to the child
* _f0sd_M_ : the standard deviation of f0 over each individual vocalisation played back to the infant
* _f0c_NM_ : the average f0 calculated over all vocalisations in each phase as produced by the infant (used in the Main Analysis)
* _f0c_M_ : the average f0 calculated over all vocalisations in each phase played back to the infant (used in the Main Analysis)
* _f0cSD_NM_ : the standard deviation of f0 all vocalisations in each phase as produced by the infant (used in the Main Analysis)
* _f0cSD_M_ : the standard deviation of f0 all vocalisations in each phase played back to the infant (used in the Main Analysis)
* Average HNR of each vocalisation produced by the child (_RMS_NM_) or played back to them (_HNR_M_)
* Average RMS of each vocalisation produced by the child (_RMSm_NM_) or played back to them (_RMSm_M_)

**N72_f0_overtime** contains the f0 values per individual timepoint. The columns are the following:
* _file_ : see above
* _start_times_ : see above
* _stop_times_ : see above
* _who_ : see above
* _voc_type_ : see above
* _phase_ : see above
* _BB_ : the unique participant ID
* _timepoint_ : time in seconds from the start of the video ;
* _f0_BBvoc_NM_ : the f0 value produced by the infant at each timepoint
* _f0_BBvoc_M_ : the f0 value played back to the infant at each timepoint
* _difference_ : the difference between the sound played back and that produced by the infant

**MT_comp.csv** reports where the child was looking at each timepoint during during the mirror task. It includes the following columns:
* _video_ : the video filename;
* _timing_sec_: time in seconds from the start of the video ;
* _phase_: mirror1 or mirror2 (respectively, before and after mark placement);
* _code_: unique ID per look type, i.e., where the child is looking, explicitly reported in the column _key_name_ (Mi = mirror, Mu = caregiver, A = away, Ta = touches or reaches for the mirror while looking away, Tm = touches or reaches for the mirror while looking at it, uncodable = when the child's gaze direction could not be determined, blink = when the child blinked, UnS = unsure);
* _FPS_ = frames per second;
* _cam_n_b_ = the camera where the gaze was captured (as two cameras were used to ensure that the direction of the child's gaze was always visible)
* _bb_nb_ = the participant unique ID

### Plot analysis
This folder (contained in "Datasets") includes the figures shown in the manuscript, generated by Script 3. 







