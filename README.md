# SOABB1
This online repository contains the data processing and analysis scripts underlying the article entitled ‘Infants recognise their own voice well before recognising their own face’, as well as the anonymised tabulated data associated with this work. 

## Repository structure

### Codes

* _analyses_MT_gaze.ipynb_ : runs the looking time analyses during the mirror task, to compare looking time to the mirror before and after the red mark is placed on the infant forehead.
* _Script1_cutFiles.ipynb_ : processes audio recordings by separating infant vocalisations from other sounds and merging vocalisations that are the same type and produced by the same child in the same phase which are less than 500ms apart. The results are stored in the .csv file with this name structure: "NX_sounds_details".
* _Script2_extractPitch.ipynb_ : extracts the fundamental frequency (f0), harmonic-to-noise (HNR) and root mean square (RMS) of the vocalisations in each phase of the experiment (experimental and baseline) with Praat, based on the .csv file generated by _Script1_cutFiles.ipynb_. To run this script, download _Pitch_BB.praat_ and _utilities_SOA.py_ (both included in this repository). Make sure to update your local path to _Pitch_BB.praat_ inside _utilities_SOA.py_. It generates a .csv file with the following name structure: "f0_HNR_RMS_NX.csv" and another one containing f0 values over time (non averaged) per vocalisation, with this name structure: "NX_f0_overtime.csv" 
* _Script3_plotResults.ipynb_ : preprocesses data, plots results and runs descriptive statistics based on the results file with the following format: "f0_HNR_RMS_NX.csv". 
* _analyse_SOABB_v2_script4_f0overtime.ipynb_ allows to visualise f0 variation over time, overall and per vocalisation.

### Datasets

* _References_audios_bb.xlsx_ contains the demographic details about the participants (e.g., age, languages spopken, sex, date of birth) as well as details and notes concerning the test (e.g., date, timing of f0 modification relative to the onset of the recording, etc). 
* _N_sounds_details.csv_ is generated at the end of Script 1 and contains the start and end times of parent and child vocalisations and the vocalisation type, the phase in which it was produced (BL: baseline - before f0 modification or EXP: experimental - after f0 modification). It does not yet include the f0, which is extracted in Script 2 based on this file. 
* _N_f0_HNR_RMS.csv_ is the final dataset generated at the end of Script 2, containing the duration, start and end times of each vocalisation, the phase in which it was produced (baseline or experimental), the vocalisation type, and who produced it (i.e., baby or mum). It also includes the average f0 for each vocalisation and the average f0 per phase per infant, along with demographic details for each participant, including age, linguistic background and other relevant information. Script 3 runs on this file.
* _N72_f0_overtime_ contains the 
* _MT_comp.csv_ reports where the child was looking at each timepoint during during the mirror task. It includes the following columns: _video_ : the video filename; _timing_sec_: time in seconds from the start of the video ; _phase_: mirror1 or mirror2 (respectively, before and after mark placement); _code_: unique ID per look type, i.e., where the child is looking, explicitly reported in _key_name_ (Mi = mirror, Mu = caregiver, A = away, Ta = touches or reaches for the mirror while looking away, Tm = touches or reaches for the mirror while looking at it, uncodable = when the child's gaze direction could not be determined, blink = when the child blinked, UnS = unsure) 

### Plot analysis
This folder (contained in "Datasets") includes the figures shown in the manuscript, generated by Script 3. 







